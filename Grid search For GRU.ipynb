{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db4b408-4b9f-4bfc-8689-e337df8ae9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frustration' 'disappointment' 'anger' 'distrust' 'disgust' 'fear'\n",
      " 'confusion' 'sadness']\n",
      "Index(['Reviewer_Name', 'Stars', 'Title_of_Review', 'Base_Review1',\n",
      "       'Base_Reviews', 'Sentiment_Score', 'Sentiment', 'sentiment', 'emotion',\n",
      "       'category', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12'],\n",
      "      dtype='object')\n",
      "Best score: 0.8641414046287537\n",
      "Best parameters: {'embedding_dim': 100, 'gru_units': 64, 'dropout': 0.2, 'optimizer': 'adam', 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Chatgptdataset.csv', encoding='latin1')\n",
    "\n",
    "unique_categories = df['category'].unique()\n",
    "print(unique_categories)\n",
    "print(df.columns)\n",
    "\n",
    "# 1. Data Preparation:\n",
    "\n",
    "# Tokenize the text:\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['Base_Reviews'])\n",
    "X = tokenizer.texts_to_sequences(df['Base_Reviews'])\n",
    "maxlen = max(len(x) for x in X)\n",
    "X = pad_sequences(X, maxlen=maxlen)\n",
    "\n",
    "# Convert categories to integers:\n",
    "categories = ['frustration', 'disappointment', 'anger', 'distrust', 'disgust', 'fear', 'confusion', 'sadness']\n",
    "y = np.array([categories.index(cat) for cat in df['category']])\n",
    "\n",
    "# One-hot encode the labels:\n",
    "y = to_categorical(y)\n",
    "\n",
    "# 2. Model creation, training, and evaluation:\n",
    "\n",
    "def train_and_evaluate_model(params):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=params['embedding_dim'], input_length=maxlen))\n",
    "    model.add(GRU(params['gru_units']))  # Replacing LSTM with GRU\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(len(categories), activation='softmax'))  # Softmax activation for multi-class\n",
    "    model.compile(optimizer=params['optimizer'], loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X, y, epochs=params['epochs'], batch_size=32, verbose=0, validation_split=0.2)\n",
    "    _, accuracy = model.evaluate(X, y, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "# 3. Hyperparameter tuning:\n",
    "param_grid = {\n",
    "    'embedding_dim': [50, 100],\n",
    "    'gru_units': [32, 64],  # Replacing lstm_units with gru_units\n",
    "    'dropout': [0.2, 0.5],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'epochs': [5, 10]\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for embedding_dim in param_grid['embedding_dim']:\n",
    "    for gru_units in param_grid['gru_units']:  # Iterating over gru_units\n",
    "        for dropout in param_grid['dropout']:\n",
    "            for optimizer in param_grid['optimizer']:\n",
    "                for epochs in param_grid['epochs']:\n",
    "                    params = {\n",
    "                        'embedding_dim': embedding_dim,\n",
    "                        'gru_units': gru_units,  # Using gru_units instead of lstm_units\n",
    "                        'dropout': dropout,\n",
    "                        'optimizer': optimizer,\n",
    "                        'epochs': epochs\n",
    "                    }\n",
    "                    score = train_and_evaluate_model(params)\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_params = params\n",
    "\n",
    "print(\"Best score:\", best_score)\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7bb068-0679-4629-af8e-d10cd01071fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
